Experiment 7: Training time ~18 hours
Setup
With random initial position for the player over the entire field and fixed ball position 
With episode length of 5 minutes
With +1000 reward for ball contact and +ve reward for moving towards the ball with high speed
Result
Agent is not moving towards the ball efficiently

Experiment 8:
Field size: 10x10, Randomize player: True, Randomize ball: True
Simulation Time: 45 secs
Done: When player touches ball
Reward: reward_vel_to_ball
Checkpoint 1: 
The player kicked the ball but the episode did not terminate.
Fixed the contact detection algorithm. Reduced Field size to 0.5x0.5. Episodes now terminate on contact with ball.

Experiment 9: 
Field size: 1x1, Randomize player: True, Randomize ball: True
Simulation Time: 45 secs
Done: When player touches ball
Reward: +100 for touching the ball, -1 per timestep
Checkpoint 1:
Field size: 10x10
Increase Reward to +10000 to show significance as accumulated score over 45 secs ~-22000.
Checkpoint 2: 
Field size: 3x3
The player is not kicking the ball sufficiently in 10x10 environment. Reducing the field size.
Checkpoint 3:
Constant reward -1 is not incentivizing the ball enough to move. Bringing back reward_vel_to_ball.
Checkpoint 4:
Increase the Mujoco min bolt speed in Configurations from 0 to 10 for faster exploration.
Fix velocity range in observation space from [0,255] to [0,20] as calculated observation space returns velocities in that range.
Conclusion:
The player is still moving like its actively avoiding the ball. The reward function needs to be verified.

Experiment 10:
Changelog: 
reward_vel_to_ball now calculates on normalized player_velocity vector.
reward_vel_to_ball is now assigned '-' sign as with '+' sign the player seems to actively avoid kicking the ball.
reward_ball_kicked changed to +100.
Conclusion:
Agent is still not decisively hitting the ball