Experiment 7: Training time ~18 hours
Setup
With random initial position for the player over the entire field and fixed ball position 
With episode length of 5 minutes
With +1000 reward for ball contact and +ve reward for moving towards the ball with high speed
Result
Agent is not moving towards the ball efficiently

Experiment 8:
Field size: 10x10, Randomize player: True, Randomize ball: True
Simulation Time: 45 secs
Done: When player touches ball
Reward: reward_vel_to_ball
Checkpoint 1: 
The player kicked the ball but the episode did not terminate.
Fixed the contact detection algorithm. Reduced Field size to 0.5x0.5. Episodes now terminate on contact with ball.

Experiment 9: 
Field size: 1x1, Randomize player: True, Randomize ball: True
Simulation Time: 45 secs
Done: When player touches ball
Reward: +100 for touching the ball, -1 per timestep
Checkpoint 1:
Field size: 10x10
Increase Reward to +10000 to show significance as accumulated score over 45 secs ~-22000.
 